{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages \n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import json\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "annotations_file = 'path\\to\\annotations'\n",
    "with open(annotations_file, 'r') as file:\n",
    "    annotations = json.load(file)\n",
    "\n",
    "# Parse annotations\n",
    "data_directory = r'\\path\\to\\directory'\n",
    "data = []\n",
    "for filename, file_data in annotations.items():\n",
    "\n",
    "    image_path = data_directory+'\\\\'+filename.split('.')[0]+'.png'\n",
    "    image = Image.open(image_path)\n",
    "    for region in file_data['regions']:\n",
    "\n",
    "        shape_attrs = region['shape_attributes']\n",
    "        region_attrs = region['region_attributes']\n",
    "        temp = {\n",
    "            'filename': filename.split('.')[0]+'.png',\n",
    "            'name': shape_attrs['name'],\n",
    "            'width': image.width,\n",
    "            'height': image.height,\n",
    "            'all_points_x': shape_attrs['all_points_x'],\n",
    "            'all_points_y': shape_attrs['all_points_y'],\n",
    "            'Type': region_attrs['Type']\n",
    "        }\n",
    "\n",
    "        #Don't include duplicates\n",
    "        if temp not in data:\n",
    "            data.append({\n",
    "                'filename': filename.split('.')[0]+'.png',\n",
    "                'name': shape_attrs['name'],\n",
    "                'width': image.width,\n",
    "                'height': image.height,\n",
    "                'all_points_x': shape_attrs['all_points_x'],\n",
    "                'all_points_y': shape_attrs['all_points_y'],\n",
    "                'Type': region_attrs['Type']\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(size, box):\n",
    "    dw = 1. / size[0]\n",
    "    dh = 1. / size[1]\n",
    "    x = (box[0] + box[1]) / 2.0\n",
    "    y = (box[2] + box[3]) / 2.0\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x * dw\n",
    "    w = w * dw\n",
    "    y = y * dh\n",
    "    h = h * dh\n",
    "    return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_polygon_to_bbox(x_coords,y_coords):\n",
    "    xmin = min(x_coords)\n",
    "    xmax = max(x_coords)\n",
    "    ymin = min(y_coords)\n",
    "    ymax = max(y_coords)\n",
    "    return [xmin, xmax, ymin, ymax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_annotations_to_yolo(data_list, output_dir, label_map):\n",
    "    annotations_by_filename = defaultdict(list)\n",
    "    \n",
    "    for data in data_list:\n",
    "        filename = data['filename']\n",
    "        width = data['width']\n",
    "        height = data['height']\n",
    "        all_points_x = data['all_points_x']\n",
    "        all_points_y = data['all_points_y']\n",
    "        label = data['Type']\n",
    "        \n",
    "        bbox = convert_polygon_to_bbox(all_points_x, all_points_y)\n",
    "        bb = convert((width, height), bbox)\n",
    "        class_id = label_map[label]\n",
    "        \n",
    "        annotations_by_filename[filename].append((class_id, bb))\n",
    "    \n",
    "    # Write annotations to YOLO format files\n",
    "    for filename, annotations in annotations_by_filename.items():\n",
    "        file_base = os.path.splitext(filename)[0]\n",
    "        with open(f'{output_dir}/{file_base}.txt', 'w') as out_file:\n",
    "            for class_id, bb in annotations:\n",
    "                out_file.write(f\"{class_id} {' '.join(map(str, bb))}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "label_map = {'Offense': 0, 'Defense': 1}  \n",
    "output_dir =r'path\\to\\output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "convert_annotations_to_yolo(data, output_dir, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs(base_dir, categories):\n",
    "    for category in categories:\n",
    "        os.makedirs(os.path.join(base_dir, category, 'images'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(base_dir, category, 'labels'), exist_ok=True)\n",
    "\n",
    "def split_dataset(image_dir, annotation_dir, train_dir, test_dir, split_ratio=0.8):\n",
    "    images = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "    annotations = [f for f in os.listdir(annotation_dir) if os.path.isfile(os.path.join(annotation_dir, f))]\n",
    "\n",
    "\n",
    "    if len(images) != len(annotations):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"Number of images and annotations do not match!\")\n",
    "        return\n",
    "\n",
    "    paired_files = list(zip(images, annotations))\n",
    "    random.shuffle(paired_files)\n",
    "    \n",
    "    train_size = int(len(paired_files) * split_ratio)\n",
    "    train_files = paired_files[:train_size]\n",
    "    test_files = paired_files[train_size:]\n",
    "    \n",
    "    for files in train_files:\n",
    "        shutil.copy(os.path.join(image_dir, files[0]), os.path.join(train_dir, 'images', files[0]))\n",
    "        shutil.copy(os.path.join(annotation_dir, files[1]), os.path.join(train_dir, 'labels', files[1]))\n",
    "    \n",
    "    for files in test_files:\n",
    "        shutil.copy(os.path.join(image_dir, files[0]), os.path.join(test_dir, 'images', files[0]))\n",
    "        shutil.copy(os.path.join(annotation_dir, files[1]), os.path.join(test_dir, 'labels', files[1]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = r'path\\to\\directory'\n",
    "    image_dir = os.path.join(base_dir, 'NFL All 22 Formations Data_Yolo_Images')\n",
    "    annotation_dir = os.path.join(base_dir, 'YOLO_labels')\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "    \n",
    "    create_dirs(base_dir, ['train', 'test'])\n",
    "    split_dataset(image_dir, annotation_dir, train_dir, test_dir, split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "data = {\n",
    "    'train': r'path\\to\\train',\n",
    "    'val': r'path\\to\\val',\n",
    "    'nc': 2,\n",
    "    'names': [\n",
    " 'Offense', 'Defense']\n",
    "}\n",
    "\n",
    "with open('model.yaml', 'w') as outfile:\n",
    "    yaml.dump(data, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8m.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust parameters if needed\n",
    "model.train(data='path\\to\\model.yaml', epochs=100, imgsz=640, batch=4,patience =7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.val(data='path\\to\\model.yaml', imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
